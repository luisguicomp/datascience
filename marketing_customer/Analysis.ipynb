{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customer Lifetime Value (CLV)\n",
    "\n",
    "- O quanto uma empresa espera ganhar de um cliente ao longo da vida\n",
    "- Número de compras, transações, etc\n",
    "- Várias equações\n",
    "    - CLV = Receita Média * margin de lucro * vida útil \n",
    "    - CLV = (Receita Média por transacão * frquencia média * margin de lucro)* vida útil \n",
    "    - CLV = (Receita Média * margin de lucro)* Taxa de retenção / Taxa de churn\n",
    "    \n",
    "- Utiliza um conjunto de cohhort para calcular a taxa de retenção (mensal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Quanto de lucro líquido um cliente em média entrega para empresa por transação?\n",
    "- Quantas transações ele faz no seu ciclo de vida de consumo dentro da empresa?\n",
    "- Qual é o tempo do ciclo de vida dele como consumidor ativo na empresa?\n",
    "\n",
    "https://clevertap.com/cltv/\n",
    "\n",
    "- A utilização do CLV resulta em um aumento de 5% na retenção e 25% no lucro;\n",
    "- Adquirir um novo cliente é entre 5x e 25x mais caro do que reter um cliente existente;\n",
    "- A probabilidade de converter um cliente existente é entre 60% e 70%;\n",
    "- Os clientes existentes gastam 67% a mais em comparação a média de novos clientes.\n",
    "\n",
    "https://thiagoacioli.com/customer-lifetime-value-o-que-%C3%A9-e-como-calcular-6db13a68e32e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract cohort sizes from the first column of cohort_counts\n",
    "cohort_sizes = cohort_counts.iloc[:,0]\n",
    "\n",
    "# Calculate retention by dividing the counts with the cohort sizes\n",
    "retention = cohort_counts.divide(cohort_sizes, axis=0)\n",
    "\n",
    "# Calculate churn\n",
    "churn = 1 - retention\n",
    "\n",
    "# Print the retention table\n",
    "print(churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean retention rate\n",
    "retention_rate = retention.iloc[:,1:].mean().mean()\n",
    "\n",
    "# Calculate the mean churn rate\n",
    "churn_rate = churn.iloc[:,1:].mean().mean()\n",
    "\n",
    "# Print rounded retention and churn rates\n",
    "print('Retention rate: {:.2f}; Churn rate: {:.2f}'.format(retention_rate, churn_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate monthly spend per customer\n",
    "monthly_revenue = online.groupby(['CustomerID','InvoiceMonth'])['TotalSum'].sum()\n",
    "\n",
    "# Calculate average monthly spend\n",
    "monthly_revenue = np.mean(monthly_revenue)\n",
    "\n",
    "# Define lifespan to 36 months\n",
    "lifespan_months = 36\n",
    "\n",
    "# Calculate basic CLV\n",
    "clv_basic = monthly_revenue * lifespan_months\n",
    "\n",
    "# Print the basic CLV value\n",
    "print('Average basic CLV is {:.1f} USD'.format(clv_basic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average revenue per invoice\n",
    "revenue_per_purchase = online.groupby(['InvoiceNo'])['TotalSum'].mean().mean()\n",
    "\n",
    "# Calculate average number of unique invoices per customer per month\n",
    "frequency_per_month = online.groupby(['CustomerID','InvoiceMonth'])['InvoiceNo'].nunique().mean()\n",
    "\n",
    "# Define lifespan to 36 months\n",
    "lifespan_months = 36\n",
    "\n",
    "# Calculate granular CLV\n",
    "clv_granular = revenue_per_purchase * frequency_per_month * lifespan_months\n",
    "\n",
    "# Print granular CLV value\n",
    "print('Average granular CLV is {:.1f} USD'.format(clv_granular))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate monthly spend per customer\n",
    "monthly_revenue = online.groupby(['CustomerID','InvoiceMonth'])['TotalSum'].sum().mean()\n",
    "\n",
    "# Calculate average monthly retention rate\n",
    "retention_rate = retention.iloc[:,1:].mean().mean()\n",
    "\n",
    "# Calculate average monthly churn rate\n",
    "churn_rate = 1 - retention_rate\n",
    "\n",
    "# Calculate traditional CLV \n",
    "clv_traditional = monthly_revenue * (retention_rate / churn_rate)\n",
    "\n",
    "# Print traditional CLV and the retention rate values\n",
    "print('Average traditional CLV is {:.1f} USD at {:.1f} % retention_rate'.format(clv_traditional, retention_rate*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purchase prediction\n",
    "\n",
    "#### Recency, Frquency , Monetary (RFM) featues\n",
    "- R = tempo desde a última transação\n",
    "- F = Número de transações em um período\n",
    "- M = Valor gasto em um período\n",
    "\n",
    "#### Passsos\n",
    "- Agrupar transações mensais (ou período desejado) por consumidor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the snapshot date\n",
    "NOW = dt.datetime(2011,11,1)\n",
    "\n",
    "# Calculate recency by subtracting current date from the latest InvoiceDate\n",
    "features = online_X.groupby('CustomerID').agg({\n",
    "  'InvoiceDate': lambda x: (NOW - x.max()).days,\n",
    "  # Calculate frequency by counting unique number of invoices\n",
    "  'InvoiceNo': pd.Series.nunique,\n",
    "  # Calculate monetary value by summing all spend values\n",
    "  'TotalSum': np.sum,\n",
    "  # Calculate average and total quantity\n",
    "  'Quantity': ['mean', 'sum']}).reset_index()\n",
    "\n",
    "# Rename the columns\n",
    "features.columns = ['CustomerID', 'recency', 'frequency', 'monetary', 'quantity_avg', 'quantity_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a pivot table counting invoices for each customer monthly\n",
    "cust_month_tx = pd.pivot_table(data=online, values='InvoiceNo',\n",
    "                               index=['CustomerID'], columns=['InvoiceMonth'],\n",
    "                               aggfunc=pd.Series.nunique, fill_value=0)\n",
    "\n",
    "# Store November 2011 data column name as a list\n",
    "target = ['2011-11']\n",
    "\n",
    "# Store target value as `Y`\n",
    "Y = cust_month_tx[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store customer identifier column name as a list\n",
    "custid = ['CustomerID']\n",
    "\n",
    "# Select feature column names excluding customer identifier\n",
    "cols = [col for col in features.columns if col not in custid]\n",
    "\n",
    "# Extract the features as `X`\n",
    "X = features[cols]\n",
    "\n",
    "# Split data to training and testing\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.25, random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize linear regression instance\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# Fit the model to training dataset\n",
    "linreg.fit(train_X, train_Y)\n",
    "\n",
    "# Predict the target variable for training data\n",
    "train_pred_Y = linreg.predict(train_X)\n",
    "\n",
    "# Predict the target variable for testing data\n",
    "test_pred_Y = linreg.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate root mean squared error on training data\n",
    "rmse_train = np.sqrt(mean_squared_error(train_Y, train_pred_Y))\n",
    "\n",
    "# Calculate mean absolute error on training data\n",
    "mae_train = mean_absolute_error(train_Y, train_pred_Y)\n",
    "\n",
    "# Calculate root mean squared error on testing data\n",
    "rmse_test = np.sqrt(mean_squared_error(test_Y, test_pred_Y))\n",
    "\n",
    "# Calculate mean absolute error on testing data\n",
    "mae_test = mean_absolute_error(test_Y, test_pred_Y)\n",
    "\n",
    "# Print the performance metrics\n",
    "print('RMSE train: {}; RMSE test: {}\\nMAE train: {}, MAE test: {}'.format(rmse_train, rmse_test, mae_train, mae_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import `statsmodels.api` module\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Initialize model instance on the training data\n",
    "olsreg = sm.OLS(train_Y, train_X)\n",
    "\n",
    "# Fit the model\n",
    "olsreg = olsreg.fit()\n",
    "\n",
    "# Print model summary\n",
    "print(olsreg.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentação\n",
    "\n",
    "- Não supervisionado\n",
    "    - Kmeans\n",
    "    - Non-negative matrix factorization (NMF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação dos dados\n",
    "- Boxcox / Log - Para ver a correlação em pares\n",
    "- StardardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KMeans' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-189b6ae9c2dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Fit KMeans algorithm on k values between 1 and 11\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m11\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mkmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m333\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwholesale_scaled_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0msse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minertia_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'KMeans' is not defined"
     ]
    }
   ],
   "source": [
    "# Elbow Criteria (To Know the cluster´s number)\n",
    "from sklearn.cluster import KMeans\n",
    "sse = {}\n",
    "\n",
    "# Fit KMeans algorithm on k values between 1 and 11\n",
    "for k in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=333)\n",
    "    kmeans.fit(wholesale_scaled_df)\n",
    "    sse[k] = kmeans.inertia_\n",
    "\n",
    "# Add the title to the plot\n",
    "plt.title('Elbow criterion method chart')\n",
    "\n",
    "# Create and display a scatter plot\n",
    "sns.pointplot(x=list(sse.keys()), y=list(sse.values()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Initialize `KMeans` with 4 clusters\n",
    "kmeans=KMeans(n_clusters=4, random_state=123)\n",
    "\n",
    "# Fit the model on the pre-processed dataset\n",
    "kmeans.fit(wholesale_scaled_df)\n",
    "\n",
    "# Assign the generated labels to a new column\n",
    "wholesale_kmeans4 = wholesale.assign(segment = kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NMF\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# Initialize NMF instance with 4 components\n",
    "nmf = NMF(4)\n",
    "\n",
    "# Fit the model on the wholesale sales data\n",
    "nmf.fit(wholesale)\n",
    "\n",
    "# Extract the components \n",
    "components = pd.DataFrame(data=nmf.components_, columns=wholesale.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização\n",
    "# Group by the segment label and calculate average column values\n",
    "kmeans3_averages = wholesale_kmeans3.groupby(['segment']).mean().round(0)\n",
    "\n",
    "# Print the average column values per each segment\n",
    "print(kmeans3_averages)\n",
    "\n",
    "# Create a heatmap on the average column values per each segment\n",
    "sns.heatmap(kmeans3_averages.T, cmap='YlGnBu')\n",
    "\n",
    "# Display the chart\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
