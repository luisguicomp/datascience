{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de sentimento dos livros da Bíblia\n",
    "\n",
    "## Luís Guilherme Ribeiro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/luisguilhermeribeiro/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/luisguilhermeribeiro/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/luisguilhermeribeiro/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coletando dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31482, 11)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importação dos dados\n",
    "df_path = \"./biblia_almeida_completa.csv\"\n",
    "df = pd.read_csv(df_path)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicando lematização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lematização reduz as palavras flexionadas adequadamente, garantindo que a palavra raiz pertença ao idioma (dicionario)\n",
    "def lem(a):\n",
    "    p = nltk.WordNetLemmatizer()\n",
    "    b = []\n",
    "    for line in a:\n",
    "\n",
    "        split_line = line.split(' ')\n",
    "        length=len(split_line)\n",
    "        new_line = []\n",
    "\n",
    "        for word in range(length):\n",
    "            if word == 0:\n",
    "                new_line.append(str(p.lemmatize(split_line[word], pos=\"v\")))\n",
    "            else:\n",
    "                new_line[0] = new_line[0] + ' ' + (str(p.lemmatize(split_line[word], pos=\"v\")))\n",
    "\n",
    "        b.append(new_line[0])\n",
    "\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['t_lem']=lem(df.texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrupamento e SVD\n",
    "\n",
    "Eu uso vetorizador e decomposição de valor singular para criar clusters de texto e mesclá-los com os dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comp1</th>\n",
       "      <th>Comp2</th>\n",
       "      <th>Testamento</th>\n",
       "      <th>Livro</th>\n",
       "      <th>Periodo</th>\n",
       "      <th>Localizacao</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Autor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.165387</td>\n",
       "      <td>0.047691</td>\n",
       "      <td>antigo</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>Persian</td>\n",
       "      <td>Israel</td>\n",
       "      <td>-500</td>\n",
       "      <td>Moises</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.061626</td>\n",
       "      <td>-0.010588</td>\n",
       "      <td>antigo</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>Persian</td>\n",
       "      <td>Israel</td>\n",
       "      <td>-500</td>\n",
       "      <td>Moises</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.079983</td>\n",
       "      <td>-0.071173</td>\n",
       "      <td>antigo</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>Persian</td>\n",
       "      <td>Israel</td>\n",
       "      <td>-500</td>\n",
       "      <td>Moises</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.108721</td>\n",
       "      <td>-0.065556</td>\n",
       "      <td>antigo</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>Persian</td>\n",
       "      <td>Israel</td>\n",
       "      <td>-500</td>\n",
       "      <td>Moises</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.070745</td>\n",
       "      <td>-0.028995</td>\n",
       "      <td>antigo</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>Persian</td>\n",
       "      <td>Israel</td>\n",
       "      <td>-500</td>\n",
       "      <td>Moises</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Comp1     Comp2 Testamento    Livro  Periodo Localizacao  Tempo   Autor\n",
       "0  0.165387  0.047691     antigo  Genesis  Persian      Israel   -500  Moises\n",
       "1  0.061626 -0.010588     antigo  Genesis  Persian      Israel   -500  Moises\n",
       "2  0.079983 -0.071173     antigo  Genesis  Persian      Israel   -500  Moises\n",
       "3  0.108721 -0.065556     antigo  Genesis  Persian      Israel   -500  Moises\n",
       "4  0.070745 -0.028995     antigo  Genesis  Persian      Israel   -500  Moises"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vetorizador (entender e explorar) [CONTA AS PRINCIPAIS PALAVRAS]\n",
    "vectorizer = TfidfVectorizer(max_df = 0.5, max_features = 1000)\n",
    "X = vectorizer.fit_transform(df.t_lem)\n",
    "# Singular Value Decomposition (SVD) = reduz a dimensão\n",
    "svd = TruncatedSVD(n_components=2, n_iter=7, random_state=42)\n",
    "X = svd.fit_transform(X)\n",
    "\n",
    "cluster_data = pd.DataFrame({'Comp1': X[:,0], 'Comp2': X[:,1], 'Testamento': df.testamento, 'Livro': df.livro, \n",
    "                             'Periodo': df.periodo, 'Localizacao': df.localizacao, 'Tempo': df.tempo, 'Autor': df.autor})\n",
    "cluster_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "sns.scatterplot('Comp1', 'Comp2', data=cluster_data, hue='Testamento', ax=axes[0], style=\"Testamento\").set_title('Por Testamento')\n",
    "sns.scatterplot('Comp1', 'Comp2', data=cluster_data, hue='Periodo', ax=axes[1], style=\"Periodo\").set_title('Por Periodo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padrões de agrupamento\n",
    "Agora vamos aplicar o algortimo kmeans a fim de identificar padrões nos agrupamento de alguns livros.\n",
    "\n",
    "Com isso, será possível entender certos padrões de escritas de alguns autores, tais como: Paulo, João e Lucas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método de elbow para saber o número ideal de clusters\n",
    "sns.set(rc={'figure.figsize':(10, 10)})\n",
    "wcss = []\n",
    "\n",
    "for i in range(1, 30):\n",
    "    clustering = KMeans(n_clusters=i, init='k-means++', random_state=42)\n",
    "    clustering.fit(X)\n",
    "    wcss.append(clustering.inertia_)\n",
    "    \n",
    "ks = range(1, 30)\n",
    "sns.lineplot(x = ks, y = wcss);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters = 5)\n",
    "kmeans.fit(X)\n",
    "Counter(kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster = df\n",
    "df_cluster['cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificando o autor do livro de Hebreus\n",
    "explicar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cts_paulo = df_cluster[df_cluster['autor'] == 'Paulo']['cluster'].value_counts()\n",
    "idx = cts_paulo.index\n",
    "i = 0\n",
    "print('Paulo')\n",
    "for x in cts_paulo:\n",
    "    perc = round(x*100/sum(cts_paulo))\n",
    "    print(idx[i], ' -> ',perc, '%')\n",
    "    i = i +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cts_lucas = df_cluster[df_cluster['autor'] == 'Lucas']['cluster'].value_counts()\n",
    "idx = cts_lucas.index\n",
    "i = 0\n",
    "print('Lucas')\n",
    "for x in cts_lucas:\n",
    "    perc = round(x*100/sum(cts_lucas))\n",
    "    print(idx[i], ' -> ',perc, '%')\n",
    "    i = i +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cts_hebreus = df_cluster[df_cluster['livro'] == 'Hebreus']['cluster'].value_counts()\n",
    "idx = cts_hebreus.index\n",
    "i = 0\n",
    "print('Hebreus')\n",
    "for x in cts_hebreus:\n",
    "    perc = round(x*100/sum(cts_hebreus))\n",
    "    print(idx[i], ' -> ',perc, '%')\n",
    "    i = i +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analisar e concluir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
